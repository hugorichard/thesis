% **************************************************************************************************************
% A Classic Thesis Style
% An Homage to The Elements of Typographic Style
%
% Copyright (C) 2018 André Miede and Ivo Pletikosić
%
% If you like the style then I would appreciate a postcard. My address
% can be found in the file ClassicThesis.pdf. A collection of the
% postcards I received so far is available online at
% http://postcards.miede.de
%
% License:
% This program is free software; you can redistribute it and/or modify
% it under the terms of the GNU General Public License as published by
% the Free Software Foundation; either version 2 of the License, or
% (at your option) any later version.
%
% This program is distributed in the hope that it will be useful,
% but WITHOUT ANY WARRANTY; without even the implied warranty of
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
% GNU General Public License for more details.
%
% You should have received a copy of the GNU General Public License
% along with this program; see the file COPYING.  If not, write to
% the Free Software Foundation, Inc., 59 Temple Place - Suite 330,
% Boston, MA 02111-1307, USA.
%
% PLEASE SEE ALSO THE AUTHORS' NOTE REGARDING THIS LICENSE
% IN THE DOCUMENTATION (ClassicThesis.pdf --> Chapter 1 / Chapter01.tex)
% **************************************************************************************************************
\RequirePackage{silence} % :-\
    \WarningFilter{scrreprt}{Usage of package `titlesec'}
    %\WarningFilter{scrreprt}{Activating an ugly workaround}
    \WarningFilter{titlesec}{Non standard sectioning command detected}
\documentclass[ twoside,openright,titlepage,numbers=noenddot,%1headlines,
                headinclude,footinclude,cleardoublepage=empty,abstract=on,
                BCOR=5mm,paper=a4,fontsize=11pt, 
                ]{scrreprt}

%********************************************************************
% Note: Make all your adjustments in here
%*******************************************************
\input{classicthesis-config}

%********************************************************************
% Bibliographies
%*******************************************************
\addbibresource{biblio.bib}
%% ADD this to create local bibs
% \addbibresource[label=ownpubs]{mypubs.bib}
% \begin{refsection}[ownpubs]
%   \small
%   \nocite{*} % is local to to the enclosing refsection
%   \printbibliography[heading=none]
% \end{refsection}


\usepackage{kky}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{caption}
\newtheorem{prop}{Prop.}
\providecommand*\theoremautorefname{Theorem}
% \newcommand{\aka}{{\em a.k.a.~}}
\newcommand{\ybu}{\underline{\yb}}
\newcommand{\xbu}{\underline{\xb}}
\newcommand{\sbbu}{\underline{\sbb}}
\newcommand{\eps}{\varepsilon}


\DeclareMathOperator{\GL}{GL}

% \usepackage[symbols,nogroupskip,sort=none]{glossaries-extra}
% \newcommand{\notation}[3]{\glsxtrnewsymbol[description={#1}]{#2}{\ensuremath{#3}}}
% \input{notations}

%********************************************************************
% Hyphenation
%*******************************************************
%\hyphenation{put special hyphenation here}

% ********************************************************************
% GO!GO!GO! MOVE IT!
%*******************************************************
\begin{document}
\frenchspacing
\raggedbottom
\selectlanguage{american} % american ngerman
%\renewcommand*{\bibname}{new name}
%\setbibpreamble{}
\pagenumbering{roman}
\pagestyle{plain}
%********************************************************************
% Frontmatter
%*******************************************************
% \include{FrontBackmatter/DirtyTitlepage}
\include{FrontBackmatter/Titlepage}
% \include{FrontBackmatter/Titleback}
% \cleardoublepage\include{FrontBackmatter/Dedication}
%\cleardoublepage\include{FrontBackmatter/Foreword}
% \cleardoublepage\include{FrontBackmatter/Abstract}
% \cleardoublepage\include{FrontBackmatter/Publications}
% \cleardoublepage\include{FrontBackmatter/Acknowledgments}
% \cleardoublepage
\include{FrontBackmatter/Contents}
%********************************************************************
% Mainmatter
%*******************************************************
\cleardoublepage
\pagestyle{scrheadings}
\pagenumbering{arabic}
%\setcounter{page}{90}
% use \cleardoublepage here to avoid problems with pdfbookmark
\cleardoublepage


\chapter{Overview}
Group studies involving large cohorts of subjects are important to draw general
conclusions about brain functional organization. However, the aggregation of
data coming from multiple subjects is challenging, since it requires accounting
for large variability in anatomy, functional topography and stimulus response
across individuals. Data modeling is especially hard for ecologically relevant
conditions such as movie watching, where the experimental setup does not imply
well-defined cognitive operations. Consequently, the statistical analysis of the
data using supervised regression-based approaches is difficult. This has
motivated the use of unsupervised learning methods that leverage the
availability of data from multiple subjects performing the same experiment;
analysis on such large groups boost statistical power.
In this thesis, we develop well principled unsupervised methods for the analysis
of neuroimaging data.

\section{Organization of the manuscript}
In part~\ref{part:background}, we give some background on statistical learning
and optimization (chapter~\ref{ch:statistical_learning}), neuroscience
(chapter~\ref{ch:neuroscience}) and unsupervised methods popular in neuroimaging (chapter~\ref{ch:review}).

The parts~\ref{part:fastsrm},~\ref{part:mvica},~\ref{part:shica}
and~\ref{part:condica} highlight four different contributions that led to
different publications.

\subsection{Fast shared response model for fMRI data}
When subjects are exposed to the same stimuli, their brain activity likely exhibits
some common, or shared response. Our goal is to recover this shared response. The \emph{shared
response model} is one possible solution to this problem.
However, the algorithm used in the shared response model does not scale well
with the size of input . This is problematic because fMRI data have a very large
size. Indeed, the fMRI data of each subject have a dimension on the order of
$p=10^5$ and a number of samples on the order of $n=10^3$. Therefore, there is a
need for faster algorithms. This will be presented in part~\ref{part:fastsrm}.

\subsection{MultiViewICA for neuroimaging data}
In order to obtain a meaningful shared response, we need to impose constrains on
the model. In the shared response model, the linear combination of the shared
sources is done under orthogonality constraints which are often deemed not
biologically plausible. A more biologically plausible constraint is
to assume independence of the recovered responses.
However, most popular methods using this assumption are partially heuristic when
multiple subjects are involved.
In part~\ref{part:mvica}, we introduce MultiViewICA: a method based on the
maximum likelihood principle that can be efficiently optimized.
In practice our method is able to recover more reliable estimate of
the shared response on fMRI and MEG data than competitors.

\paragraph{Published work}
\fullcite{richard2020modeling}

\subsection{Shared ICA for neuroimaging data}
The model used in MultiViewICA allows the response of each subject to differ
from the stereotypical response. However, it is assumed that the deviation is on
the same order of magnitude for all subjects and all components.
In Shared ICA, we use a more general model that allows to model different
deviations form the stereotypical response depending on the subject considered
and/or on the response. Importantly, the difference between subjects can be used
as an additional source of information to recover an even better estimate of the
shared response. In practice, we observe that Shared ICA improves upon
MultiViewICA. This work will be presented in part~\ref{part:shica}.

\paragraph{Published work} This work has been submitted to NeurIPS 2021.

\subsection{Conditional ICA}
Our results suggest that ICA is a good generative model for fMRI data. Can it be
used to perform data augmentation ? We design a data augmentation method, that
leverages the large amount of (unlabeled) resting state data to generate
realistic fake task data from a small set of images.
Our data augmentation method yields an improvement in classification accuracy on
eight large datasets. This will be discussed in part~\ref{part:condica}.

\paragraph{Published work}
\fullcite{tajini2021functional} (co-first authorship with equal contribution)

\subsection{Softwares}
The implementation of the methods developed in this thesis is open source and
available on Github. Some of the code we wrote has made its way to bigger
packages. 

\subsubsection{Mvlearn}
Mvlearn~\cite{perry2020mvlearn} is a Python package for multiview learning tools. It offers reference
implementations for algorithms and methods related to multiview learning.
Its API is close to the scikit-learn~\cite{abraham2014machine} one, making it
easy to learn.
We have implemented the GroupICA, GroupPCA and MultiViewICA modules of mvlearn.

\paragraph{Published work}
\fullcite{perry2020mvlearn}



\subsubsection{Brainiak}
Brainiak~\cite{kumar2020brainiak}, is a Python package that applies machine
learning methods to neuroimaging data. Its API is the same as in scikit-learn
and it includes modules such as Representational Similarity Analysis or Shared
response modeling.
We have implemented the FastSRM module of Brainiak.


\paragraph{Published work}
\fullcite{kumar2020brainiak}

\section{Chapter ordering}
The appendices can be skipped at first read.
Chapters~\ref{ch:statistical_learning},~\ref{ch:neuroscience} and~\ref{ch:review} present the necessary background.
The reader more interested in the
theory should first read
chapters~\ref{ch:fastsrm1},~\ref{ch:mvica1},~\ref{ch:shica}
and~\ref{ch:condica}. Chapters~\ref{ch:fastsrm2},~\ref{ch:mvica2},~\ref{ch:shica2}
and~\ref{ch:condica2} focus on practical results.







\part{Background concepts}
\label{part:background}
\chapter{Statistical learning and optimization}
\label{ch:statistical_learning}
\input{Chapters/learning_theory.tex}
\chapter{Neuroscience background}
\label{ch:neuroscience}
\input{Chapters/neuroscience.tex}
\chapter{Review of selected unsupervised methods popular in neuroimaging studies}
\label{ch:review}
\input{Chapters/review.tex}
\part{FastSRM: An efficient implementation of the shared response model}
\label{part:fastsrm}
\chapter{FastSRM theory}
\label{ch:fastsrm1}
\input{Chapters/fastsrm.tex}
\chapter{FastSRM experiments}
\label{ch:fastsrm2}
\input{Chapters/fastsrm_exp.tex}
\part{MultiView ICA}
\label{part:mvica}
\chapter{MultiView ICA theory}
\label{ch:mvica1}
\input{Chapters/multiviewica.tex}
\chapter{MultiView ICA in practice}
\label{ch:mvica2}
\input{Chapters/multiviewica_exp.tex}
\part{Shared ICA}
\label{part:shica}
\chapter{Shared ICA theory}
\label{ch:shica}
\input{Chapters/shica.tex}
\chapter{Shared ICA in practice}
\label{ch:shica2}
\input{Chapters/shica_exp.tex}
\part{CondICA}
\label{part:condica}
\chapter{CondICA Theory}
\label{ch:condica}
\input{Chapters/condica.tex}
\chapter{CondICA in practice}
\label{ch:condica2}
\input{Chapters/condica_exp.tex}

\part{Conclusion}
\chapter{Conclusion}
In this thesis, we have presented three contributions that allow to tackle
inter-subject variability in neuroimaging, and a data augmentation method for fMRI data.

First, in chapter~\ref{ch:fastsrm1} and chapter~\ref{ch:fastsrm2}, we develop an
atlas based procedure that is shown to accelerate significantly the existing
procedure for performing dimension reduction of fMRI data in a multi-subject
context with provably no loss of performance. It is now possible to apply these
algorithms in big datasets where the number of subjects is of the order of
several hundreds, with several thousand samples and several hundred thousand features.

Then, we propose in chapter~\ref{ch:mvica1} and chapter~\ref{ch:mvica2}
a novel unsupervised algorithm, MultiViewICA, that reveals latent sources observed through different views. Using an independence assumption, we have demonstrated that the model is identifiable, provided that the latent
sources are not Gaussian. In contrast to previous approaches, the proposed model leads to a closed-form likelihood, which we then optimize efficiently using a dedicated alternate quasi-Newton approach.
Therefore, our approach enjoys the statistical guarantees of maximum-likelihood
theory, while still being tractable. MultiViewICA outperforms other unsupervised
methods used in fMRI and MEG in the context of shared response modeling. However,
it assumes the same level of noise for all
subjects, which does not model properly between-subjects variability.

In chapter~\ref{ch:shica} and chapter~\ref{ch:shica2}, we extend MultiViewICA so
that it offers a more realistic noise model. The so-called ShICA model is a principled unifying solution to the problems of shared response modelling and GroupICA. ShICA is able to use both the diversity of Gaussian variances and non-Gaussianity for optimal estimation. We presented two algorithms to fit the model: ShICA-J, a fast algorithm that uses noise diversity, and ShICA-ML, a maximum likelihood approach that can separate Gaussian and non-Gaussian components. ShICA algorithms come with principled procedures for shared components estimation, as well as adaptation and estimation of noise levels in each view (subject) and component.
In practice ShICA outperforms MVICA and other unsupervised methods used in the
context of shared response modeling.

Lastly, we introduce in chapter~\ref{ch:condica} and chapter~\ref{ch:condica2} a data
augmentation method based on ICA that outperforms deep learning algorithms in
terms of decoding accuracy while being much faster.


\subsection{Other code contributions}
We have contributed to other large open source projects such as scikit-learn~\cite{abraham2014machine}.


\section{Contributions outside of the scope of the thesis}
Some of the contributions we have made during the thesis were outside of its
scope. We now present these contributions succinctly.

\subsection{A deep approach to model complex stimuli}
In this work, we learn a model to predict fMRI data of subjects watching a movie
from the activities of a deep neural network exposed to the same movie. The neural network is previously trained to perform action recognition on a large corpus of movies.
The association of activity in visual areas with the different layers of the
deep architecture displays complexity-related contrasts across visual areas and
reveals a striking foveal/peripheral dichotomy.

\paragraph{Published work}
\fullcite{richard2018optimizing}

\subsection{Predicting resting state from fMRI}
In this work, we predict task contrasts from rest fMRI data using a piecewise
  linear model. This model is shown to outperform linear models and a fully
  connected neural network.

  
\paragraph{Published work}
\fullcite{dohmatob2021brain}

\subsection{An optimal transport approach to hyperalignment}
In this work, we benchmark optimal transport, ridge regression and scaled
Procrustes to align the data of two
subjects. Optimal Transport Ridge regression seems to be the best method.

\paragraph{Published work}
\fullcite{bazeille2019local}

\section{A note about resources used}
All the code is written in Python.
We use Matplotlib for plotting~\cite{hunter2007matplotlib} , scikit-learn for
machine-learning pipelines~\cite{pedregosa2011scikit}, MNE for MEG
processing~\cite{gramfort2013meg}, Nilearn for fMRI processing and for its CanICA implementation~\cite{abraham2014machine}, Brainiak~\cite{kumar2020brainiak} for its SRM implementation. 
% 

\textbf{XXX Overall the conclusion lacks insight ? What could be the impact of your work ? its limitations ? Future directions ?}


\cleardoublepage\include{FrontBackmatter/Bibliography}

\appendix
\part{Appendices}
\chapter{MultiViewICA}
\input{Chapters/multiviewica_app.tex}
\chapter{ShICA}
\input{Chapters/shica_app.tex}

% % \cleardoublepage\include{FrontBackmatter/Declaration}
% % \cleardoublepage\include{FrontBackmatter/Colophon}
% % ********************************************************************
% % Game Over: Restore, Restart, or Quit?
% %*******************************************************
\end{document}
% ********************************************************************
