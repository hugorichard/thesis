% **************************************************************************************************************
% A Classic Thesis Style
% An Homage to The Elements of Typographic Style
%
% Copyright (C) 2018 André Miede and Ivo Pletikosić
%
% If you like the style then I would appreciate a postcard. My address
% can be found in the file ClassicThesis.pdf. A collection of the
% postcards I received so far is available online at
% http://postcards.miede.de
%
% License:
% This program is free software; you can redistribute it and/or modify
% it under the terms of the GNU General Public License as published by
% the Free Software Foundation; either version 2 of the License, or
% (at your option) any later version.
%
% This program is distributed in the hope that it will be useful,
% but WITHOUT ANY WARRANTY; without even the implied warranty of
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
% GNU General Public License for more details.
%
% You should have received a copy of the GNU General Public License
% along with this program; see the file COPYING.  If not, write to
% the Free Software Foundation, Inc., 59 Temple Place - Suite 330,
% Boston, MA 02111-1307, USA.
%
% PLEASE SEE ALSO THE AUTHORS' NOTE REGARDING THIS LICENSE
% IN THE DOCUMENTATION (ClassicThesis.pdf --> Chapter 1 / Chapter01.tex)
% **************************************************************************************************************
\RequirePackage{silence} % :-\
    \WarningFilter{scrreprt}{Usage of package `titlesec'}
    %\WarningFilter{scrreprt}{Activating an ugly workaround}
    \WarningFilter{titlesec}{Non standard sectioning command detected}
\documentclass[ twoside,openright,titlepage,numbers=noenddot,%1headlines,
                headinclude,footinclude,cleardoublepage=empty,abstract=on,
                BCOR=5mm,paper=a4,fontsize=11pt, 
                ]{scrreprt}

%********************************************************************
% Note: Make all your adjustments in here
%*******************************************************
\input{classicthesis-config}

%********************************************************************
% Bibliographies
%*******************************************************
\addbibresource{biblio.bib}
%% ADD this to create local bibs
% \addbibresource[label=ownpubs]{mypubs.bib}
% \begin{refsection}[ownpubs]
%   \small
%   \nocite{*} % is local to to the enclosing refsection
%   \printbibliography[heading=none]
% \end{refsection}


\usepackage{kky}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{caption}
\newtheorem{prop}{Prop.}
\providecommand*\theoremautorefname{Theorem}
% \newcommand{\aka}{{\em a.k.a.~}}
\newcommand{\ybu}{\underline{\yb}}
\newcommand{\xbu}{\underline{\xb}}
\newcommand{\sbbu}{\underline{\sbb}}
\newcommand{\eps}{\varepsilon}
\newcommand{\blue}[1]{{\color{blue} #1}}


\DeclareMathOperator{\GL}{GL}

% \usepackage[symbols,nogroupskip,sort=none]{glossaries-extra}
% \newcommand{\notation}[3]{\glsxtrnewsymbol[description={#1}]{#2}{\ensuremath{#3}}}
% \input{notations}

%********************************************************************
% Hyphenation
%*******************************************************
%\hyphenation{put special hyphenation here}

% ********************************************************************
% GO!GO!GO! MOVE IT!
%*******************************************************
\begin{document}
\frenchspacing
\raggedbottom
\selectlanguage{american} % american ngerman
%\renewcommand*{\bibname}{new name}
%\setbibpreamble{}
\pagenumbering{roman}
\pagestyle{plain}
%********************************************************************
% Frontmatter
%*******************************************************
% \include{FrontBackmatter/DirtyTitlepage}
\include{FrontBackmatter/Titlepage}
% \include{FrontBackmatter/Titleback}
% \cleardoublepage\include{FrontBackmatter/Dedication}
%\cleardoublepage\include{FrontBackmatter/Foreword}
\cleardoublepage\include{FrontBackmatter/Abstract}
% \cleardoublepage\include{FrontBackmatter/Publications}
\cleardoublepage\include{FrontBackmatter/Acknowledgments}
% \cleardoublepage
\include{FrontBackmatter/Contents}
%********************************************************************
% Mainmatter
%*******************************************************
\cleardoublepage
\pagestyle{scrheadings}
\pagenumbering{arabic}
%\setcounter{page}{90}
% use \cleardoublepage here to avoid problems with pdfbookmark
\cleardoublepage


\chapter{Overview}

\section{Introduction}

\subsection{Controlled experiments in cognitive brain imaging}
When a subject is reading a sentence or when she is listening to a sentence, her
brain activity is expected to differ. In order to measure where it differs and
by which amount, one can perform a controlled experiment. The controlled
experiment comes with a design matrix that describes the features driving her
brain activation across time. 
%
In the above case, the occurrences of the subject listening to a sentence or reading a sentence are encoded in a design matrix.
%
Then, a model is introduced to explain how
the design matrix relates to brain activity.
A simple model can consider that brain activity only differs when
the task differs and therefore have a stereotypical representation of
brain activity when she is reading a sentence and another one when she is
listening to a sentence.
While this model may simplify the reality
(two repetitions of the same task would never yield exactly the same pattern or amount of brain activity), it
is easy to interpret: the two stereotypical representations of each task can easily be
 compared and analyzed. 

This procedure naturally extends to multiple subjects. Indeed, a model can be
fit independently for each subject using the same design matrix.

\subsection{Naturalistic stimuli}
While controlled experiments give some insights about brain functionality,
the subjects' experience is far from their every-day life.
Naturalistic stimuli are meant to overcome this issue. Example of naturalistic stimuli include movie watching, music listening or resting (subjects are just asked to lie still in the scanner without further instruction).
While there is a broad interest in understanding
how the brain reacts in such ecological conditions, the recorded brain activity
is difficult to analyze. In particular, design matrices are notoriously difficult
to construct for naturalistic stimuli.

\subsection{Component analysis}
A possible solution is to learn the design matrix as part of the model.
The widely used independent component analysis applied on the data of one
subject extracts a set of components that are
maximally independent. Such components give a plausible design matrix as each
component may be seen as a different set of features driving brain activity.
However, many questions remain. How do we efficiently generalize such methods to
multi-subject data ? How to measure their performance ? Why is it useful to
construct a generative model for neuroimaging data ?
In this thesis, we develop well principled unsupervised methods for component
analysis of neuroimaging data.

\section{Organization of the manuscript}
In part~\ref{part:background}, we give some background on statistical learning
and optimization (chapter~\ref{ch:statistical_learning}), neuroscience
(chapter~\ref{ch:neuroscience}) and unsupervised methods popular in neuroimaging (chapter~\ref{ch:review}).

The parts~\ref{part:fastsrm},~\ref{part:mvica},~\ref{part:shica}
and~\ref{part:condica} highlight four different contributions that led to
different publications.

\subsection{Fast shared response model for fMRI data}
When subjects are exposed to the same stimuli, their brain activity likely exhibits
some common, or shared response. Our goal is to recover this shared response. The \emph{shared
response model} is one possible solution to this problem.
However, the algorithm used in the shared response model does not scale well
with the size of input . This is problematic because fMRI data have a very large
size. Indeed, the fMRI data of each subject have a dimension on the order of
$p=10^5$ and a number of samples on the order of $n=10^3$. Therefore, there is a
need for faster algorithms. This will be presented in part~\ref{part:fastsrm}.

\subsection{MultiViewICA for neuroimaging data}
In order to obtain a meaningful shared response, we need to impose constraints on
the model. In the shared response model, the linear combination of the shared
sources is done under orthogonality constraints which are often deemed not
biologically plausible. A more biologically plausible constraint is
to assume independence of the recovered responses.
However, most popular methods using this assumption are partially heuristic when
multiple subjects are involved.
In part~\ref{part:mvica}, we introduce MultiViewICA: a method based on the
maximum likelihood principle that can be efficiently optimized.
In practice our method is able to recover more reliable estimate of
the shared response on fMRI and MEG data than competitors.

\paragraph{Published work} (Spotlight)
\fullcite{richard2020modeling}

\subsection{Shared ICA for neuroimaging data}
The model used in MultiViewICA allows the response of each subject to differ
from the stereotypical response. However, it is assumed that the deviation is on
the same order of magnitude for all subjects and all components.
In Shared ICA, we use a more general model that allows to model different
deviations from the stereotypical response depending on the subject considered
and/or on the response. Importantly, the difference between subjects can be used
as an additional source of information to recover an even better estimate of the
shared response. In practice, we observe that Shared ICA improves upon
MultiViewICA. This work will be presented in part~\ref{part:shica}.

\paragraph{Published work} 
\fullcite{richard2021model}

\subsection{Conditional ICA}
Our results suggest that ICA is a good generative model for fMRI data. Can it be
used to perform data augmentation ? We design a data augmentation method, that
leverages the large amount of (unlabeled) resting state data to generate
realistic fake task data from a small set of images.
Our data augmentation method yields an improvement in classification accuracy on
eight large datasets. This will be discussed in part~\ref{part:condica}.

\paragraph{Published work}
\fullcite{tajini2021functional} (Oral, co-first authorship with equal contribution)

\section{Chapter ordering}
The appendices can be skipped at first read.
Chapters~\ref{ch:statistical_learning},~\ref{ch:neuroscience} and~\ref{ch:review} present the necessary background.
The reader more interested in the
theory should first read
chapters~\ref{ch:fastsrm1},~\ref{ch:mvica1},~\ref{ch:shica}
and~\ref{ch:condica}. Chapters~\ref{ch:fastsrm2},~\ref{ch:mvica2},~\ref{ch:shica2}
and~\ref{ch:condica2} focus on practical results.







\part{Background concepts}
\label{part:background}
\chapter{Statistical learning and optimization}
\label{ch:statistical_learning}
\input{Chapters/learning_theory.tex}
\chapter{Neuroscience background}
\label{ch:neuroscience}
\input{Chapters/neuroscience.tex}
\chapter{Review of selected unsupervised methods popular in neuroimaging studies}
\label{ch:review}
\input{Chapters/review.tex}
\part{FastSRM: An efficient implementation of the shared response model}
\label{part:fastsrm}
\chapter{FastSRM theory}
\label{ch:fastsrm1}
\input{Chapters/fastsrm.tex}
\chapter{FastSRM experiments}
\label{ch:fastsrm2}
\input{Chapters/fastsrm_exp.tex}
\part{MultiView ICA}
\label{part:mvica}
\chapter{MultiView ICA theory}
\label{ch:mvica1}
\input{Chapters/multiviewica.tex}
\chapter{MultiView ICA in practice}
\label{ch:mvica2}
\input{Chapters/multiviewica_exp.tex}
\part{Shared ICA}
\label{part:shica}
\chapter{Shared ICA theory}
\label{ch:shica}
\input{Chapters/shica.tex}
\chapter{Shared ICA in practice}
\label{ch:shica2}
\input{Chapters/shica_exp.tex}
\part{CondICA}
\label{part:condica}
\chapter{CondICA Theory}
\label{ch:condica}
\input{Chapters/condica.tex}
\chapter{CondICA in practice}
\label{ch:condica2}
\input{Chapters/condica_exp.tex}

\part{Conclusion}

\chapter{Conclusion}
\section{A note about resources used}
All the code is written in Python.
We use Matplotlib for plotting~\cite{hunter2007matplotlib} , scikit-learn for
machine-learning pipelines~\cite{pedregosa2011scikit}, MNE for MEG
processing~\cite{gramfort2013meg}, Nilearn for fMRI processing and for its CanICA implementation~\cite{abraham2014machine}, Brainiak~\cite{kumar2020brainiak} for its SRM implementation. 


\section{Contributions outside of the scope of the thesis}
Some of the contributions we have made during the thesis extended beyond the scope of multivariate decompositions. We now present these contributions succinctly.

\subsection{A deep approach to model complex stimuli}
In this work, we learn a model to predict fMRI data of subjects watching a movie
from the activities of a deep neural network exposed to the same movie. The neural network is previously trained to perform action recognition on a large corpus of movies.
The association of activity in visual areas with the different layers of the
deep architecture displays complexity-related contrasts across visual areas and
reveals a striking foveal/peripheral dichotomy.

\paragraph{Published work}
\fullcite{richard2018optimizing}

\subsection{Predicting resting state from fMRI}
In this work, we predict task contrasts from rest fMRI data using a piecewise
  linear model. This model is shown to outperform linear models and a fully
  connected neural network.

  
\paragraph{Published work}
\fullcite{dohmatob2021brain}

\subsection{An optimal transport approach to hyperalignment}
In this work, we benchmark optimal transport, ridge regression and scaled
Procrustes to align the data of two
subjects. Optimal Transport and Ridge regression outperformed alternatives in that task.

\paragraph{Published work}
\fullcite{bazeille2019local}


\subsection{Software}
The implementation of the methods developed in this thesis is freely available on Github \url{https://github.com/hugorichard}. Some of the code we wrote has made its way to bigger packages. 

\subsubsection{Mvlearn}
Mvlearn~\cite{perry2020mvlearn} is a Python package for multiview learning tools. It offers reference
implementations for algorithms and methods related to multiview learning.
Its API is close to the scikit-learn~\cite{abraham2014machine} one, making it
easy to learn.
We have implemented the GroupICA, GroupPCA and MultiViewICA modules of mvlearn.

\paragraph{Published work}
\fullcite{perry2020mvlearn}



\subsubsection{Brainiak}
Brainiak~\cite{kumar2020brainiak, kumar2020brainiak2}, is a Python package that applies machine
learning methods to neuroimaging data. Its API is the same as in scikit-learn
and it includes modules such as Representational Similarity Analysis or Shared
response modeling.
We have implemented the FastSRM module of Brainiak.


\paragraph{Published work}
\fullcite{kumar2020brainiak2}

\section{Conclusion}
In this thesis, we have presented three methods to perform component
analysis of multi-subject neuroimaging data and a data augmentation method for
fMRI data.

First, in chapter~\ref{ch:fastsrm1} and chapter~\ref{ch:fastsrm2}, we have developed an
atlas based procedure that is shown to accelerate significantly the existing
procedure for performing dimension reduction of fMRI data in a multi-subject
context with provably no loss of performance. It is now possible to apply these
algorithms in big datasets where the number of subjects is of the order of
several hundreds, with several thousand samples and several hundred thousand features.

Then, we have proposed in chapter~\ref{ch:mvica1} and chapter~\ref{ch:mvica2}
a novel unsupervised algorithm, MultiViewICA, that reveals latent sources observed through different views. Using an independence assumption, we have demonstrated that the model is identifiable, provided that the latent
sources are not Gaussian. In contrast to previous approaches, the proposed model leads to a closed-form likelihood, which we then optimize efficiently using a dedicated alternate quasi-Newton approach.
Therefore, MultiViewICA enjoys the statistical guarantees of maximum-likelihood
theory, while still being tractable. MultiViewICA outperforms other unsupervised
methods used to process fMRI and MEG data in the context of shared response modeling. However,
it assumes the same level of noise in all
subjects, which does not model properly between-subjects variability.

In chapter~\ref{ch:shica} and chapter~\ref{ch:shica2}, we have extended MultiViewICA in orter to deal with source noise heteroscedasticity.
In practice ShICA outperforms MultiViewICA and other unsupervised methods used in the
context of shared response modeling.

Lastly, we have introduced in chapter~\ref{ch:condica} and chapter~\ref{ch:condica2} a data
augmentation method based on ICA that outperforms deep learning algorithms in
terms of decoding accuracy while being much faster.

\section{Future work and perspectives}

Combined with the FastSRM algorithm, MultiViewICA and ShICA yield a novel way to
make use of multi-view data. They yield a set of operators per view that map
the data of each view to a shared response, reducing the variability between views.
In principle, reducing the variability between views should facilitate the
understanding of the data and therefore increase the performance of
classification based tasks such as contrast maps labeling, automatic diagnosis
or age prediction. Investigating to which extend these benefits are observed
could be the topic of future research.

A second practical direction would be to apply our
methods to different neuroimaging settings in which assumptions differ
from ours. This thesis is geared towards naturalistic imaging, where the temporal response is assumed to be shared
across subjects. We see at least two other neuroimaging settings in which our
methods can be useful. The first
one is the analysis of resting state data assuming that spatial topographies are
shared across subjects. In this setting, the spatial topographies become the
common components while the mixing operators correspond to a set of time-courses.
In practice, transposing the data is enough to enforce such assumptions.
A second one is the analysis of MEG / EEG data assuming both a spatial and
temporal mixing. This can be done in practice by stacking the features of
consecutive samples.

In terms of methods, we have treated separately dimension reduction
(chapter~\ref{ch:fastsrm1}) and source identification (chapter~\ref{ch:mvica1}
and chapter~\ref{ch:shica}). Future work might focus on understanding how these
two steps can be performed jointly. Another possible extension in the case of
naturalistic stimuli, is to assume that mixing matrices are close to each other.
Indeed, as such matrices represent spatial topographies, such prior makes sense.
Lastly, our data augmentation method does not make use of our understanding of
multiview datasets. This constitutes an exciting direction of research.


% 

\cleardoublepage\include{FrontBackmatter/Bibliography}

\appendix
\part{Appendices}
\chapter{MultiViewICA}
\input{Chapters/multiviewica_app.tex}
\chapter{ShICA}
\input{Chapters/shica_app.tex}

% % \cleardoublepage\include{FrontBackmatter/Declaration}
% % \cleardoublepage\include{FrontBackmatter/Colophon}
% % ********************************************************************
% % Game Over: Restore, Restart, or Quit?
% %*******************************************************
\end{document}
% ********************************************************************
