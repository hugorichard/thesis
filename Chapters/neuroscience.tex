In the previous chapter, we have introduced some background on statistics and
optimization.
In this chapter, we present the necessary background on the data used in this
thesis.
In our experiments, we use functional magnetic resonance imaging (fMRI) or
magnetoencephalograpy (MEG) data. As will be seen in this chapter, these two modalities have very different
characteristics.

\section{Functional magnetic resonance imaging (fMRI)}
This section relies on the handbook of fMRI data analysis~\cite{poldrack2011handbook}.

\subsection{The BOLD signal and hemodynamic response}
The story of fMRI begins with the discovery of the blood-oxygen-level-dependent
(BOLD) imaging contrast in 1990 by Ogawa~\cite{ogawa1990brain}. When neurons
fire, they consume oxygen and therefore, the level of oxygen in blood changes (it is actually over-compensated by blood supply).
Since oxygenated and deoxygenated blood (oxyhemoglobin
and deoxyhemoglobin) do not have the same magnetic susceptibility, changes in
the oxygen level in blood can be tracked by a magnetic resonance imaging (MRI) scanner.

When a short stimuli occurs, the relative change in the MRI signal (BOLD
signal) is not instantaneous. The typical response to a short stimuli follows the
curve displayed in figure~\ref{fig:hrf} and is called the \emph{hemodynamic response}.
The BOLD signal can be seen as the convolution of neural activation with the hemodynamic response.

\begin{figure}
  \center
  \includegraphics[scale=0.8]{figures/neuroscience/hrf.pdf}
  \caption{A model of the hemodynamic response function}
  \label{fig:hrf}
\end{figure}

\subsection{Spatial and temporal resolution of fMRI data}
The success of fMRI is due to its advantages compared to positron
emission topography (PET) that uses radioactive tracers to follow glucose or water levels.
PET and fMRI both have a spatial resolution of a few millimeters (which still
encompasses several hundred thousands of neurons).
However, while taking an image with PET takes about a minute, it takes on
the order of 2s to produce with fMRI.
In addition, fMRI is non-invasive and, unlike PET, it does not involve being exposed to radioactive tracers.

\subsection{Experimental designs}
In \emph{resting state} fMRI, subjects are instructed to lie still in the scanner without further instruction.
This kind of data can be used to extract networks that highlight regions that tend to co-activate.
This contrasts with \emph{task} fMRI, in which subjects have to comply with specific instructions.
In task fMRI, two types of experimental designs are widespread.
\emph{Block designs} are suited to functional
imaging modalities with low temporal resolutions.
In block designs, subjects are exposed to a continuous stimulus that lasts of a
rather long period of time before it switches to another.
This contrasts with \emph{event related designs} that are only suited to modalities with a finer time resolution. In event related designs, a sequence of short events are presented and separated by a time window (inter-stimulus interval).
When the inter-stimulus interval is shorter than the length of the hemodynamic response, we talk about ``fast'' even related designs.
While block designs or event related designs are controlled designs,
a rising trend is to use more naturalistic paradigms that are unconstrained from
behavioral manipulations and thus, more ecological with respect to real-world conditions.
In such naturalistic paradigms, referred to as \emph{naturalistic task fMRI} in
this thesis, subjects are exposed to \emph{naturalistic stimuli} such as movie
watching or audio track listening. These kinds of stimuli constitute a middle ground
between resting state and task fMRI data as activations are time-locked but the
environment is not as controlled as in a typical task fMRI setting.
%
In this thesis, we use mostly \emph{naturalistic task fMRI}, as one of our motivations is to propose a suitable framework to analyse such data.

\subsection{Preprocessing}
The fMRI signal is particularly noisy. Several techniques are used to reduce the noise and enhance the quality of the data.

\subsubsection{Distortion correction}
In the MRI scanner, a constant magnetic field is applied. However, in areas
where there is an air/tissue interface, the magnetic field is distorted leading to errors in
the localization of voxels near the sinus or ears. However, most scanners come
with a map quantifying the distance that each voxel has been shifted. By
inverting the map, one can try and recover the correct location of voxels.


\subsubsection{Slice timing correction}
Images are acquired in slices, a few slices at a time, so that different voxels are acquired at different times.
In order to correct for this effect, a reference slice is chosen and other
slices are interpolated so that we can consider that all voxels are acquired at the same time. 

\subsubsection{Motion correction}
Head motion causes massive distortion of the signal. Such effects are corrected by
chosing a reference image and applying a rigid body transformations so that other
images match the orientation and localization of the reference image. One also
records estimated head movements parameters so that they can be regressed out.
However, if the task is correlated with head motion, this regression can lead to
a loss of information.

\subsubsection{Spatial smoothing}
Spatial smoothing blurs the image through the application of a Gaussian kernel with a given width (in mm). When the signal of interest has a large spatial extend, smoothing increases the signal to noise ratio. 
Smoothing is also used as a way to decrease between-subject variability.
In our experiments, we usually don't apply smoothing in order to measure how our
methods are able to handle fined grained details. While there is currently no
consensus on smoothing, we observe that a smoothing of 3~mm generally improves
most analysis on fMRI data.

\subsubsection{Frequency filtering}
Heating of the scanner causes a low temporal frequency noise to appear. In order
to remove such noise, a high-pass filtering is applied with a cut-off frequency
of $0.01 Hz$. Sometimes a low-pass filter with a cut-off frequency of $0.1$ Hz is also used since artifacts induced by motion are usually of higher frequency than the signal of interest.

\subsubsection{Spatial normalization}
Each subject has a brain of different size and shape.
The goal of spatial normalization is to align brain images of different subjects in order to reduce anatomical variability.

The most widespread technique is to register all images into the Montreal Neurological
Institute template (MNI template). The
MNI template is built from 305 anatomical images that are aligned based on
anatomical features via a non-linear registration model.
The non-linear registration model uses rigid body transformations followed
by non-linear diffeomorphic deformations to better match brain shape. 

The projection of fMRI data to the MNI space proceeds in two steps.
First, a high dimensional anatomical image of each
subject is aligned on the MNI template. Then the fMRI images of each subjects are 
aligned on the anatomical image of the same subject (this step is called
\emph{co-registration}). The fMRI images are mapped to the MNI template by
composing the two transformations.


\subsubsection{Masking}
It is often the case that only a subpart of the brain is of interest. When this is the case, we use a mask to only keep the set of voxels corresponding to particular locations defined by the mask.
In the case of our experiments, we use a gray-matter mask, since this is the
only part that matters when one wants to capture functional activations in the
brain that reflect behavioral responses.

\subsubsection{Runs}
For the comfort of participants and to ensure their active participation, it is in general not possible to use the scanner without interruptions for more than 15 minutes.  When long acquisitions must be
performed, they are split into short runs of approximately 15 minutes.


\subsection{Example of fMRI Datasets}
\label{srm:datasets:fmri}
In this subsection we provide examples of fMRI datasets. These datasets will be used to evaluate the methods developed in this thesis.
Datasets are preprocessed with FSL \url{http://fsl.fmrib.ox.ac.uk/fsl}  and SPM \url{https://www.fil.ion.ucl.ac.uk/spm/software} using slice timing correction, distortion correction spatial realignment, co-registration to the T1 image and affine transformation of the functional volumes to a template brain (MNI).
Using Nilearn \cite{abraham2014machine}, preprocessed data are masked (using a full brain mask available at
\url{http://cogspaces.github.io/assets/data/hcp_mask.nii.gz}), detrended and
standardized (so that any voxel's timecourse has zero mean and unit variance).
We also apply a high-pass filter and a low-pass filter with cut-off frequencies of 0.01 Hz and 0.1 Hz respectively).

\subsubsection{Sherlock}
In the \emph{SHERLOCK} dataset, 17 participants are watching "Sherlock" BBC TV show (episode 1). 
% 
These data are downloaded from \url{http://arks.princeton.edu/ark:/88435/dsp01nz8062179}. 
% 
Data were acquired using a 3T scanner with an isotropic spatial resolution of 3~mm. 
% 
More information including the preprocessing pipeline is available in \cite{sherlock}.
% 
Subject 5 is removed because of missing data, leaving us with 16 participants.
% 
Although SHERLOCK data contains originally only 1 run, we split it into 4 blocks of 395 timeframes and one block of 396 timeframes for the needs of our experiments. 

\subsubsection{Forrest}
In the \emph{FORREST} dataset, 20 participants are listening to an audio version of the movie Forrest Gump.
% 
FORREST data are downloaded from OpenNeuro~\cite{poldrack2013toward}. 
% 
Data were acquired using a 7T scanner with an isotropic spatial resolution of 1 mm (see more details in \cite{hanke2014high}.
% 
More information about the forrest project can be found at \url{http://studyforrest.org}.
% 
Subject 10 and run 8 are discarded because of missing data.
% 
We therefore use full brain data of 19 subjects split in 7 runs of respectively 451, 441, 438, 488, 462, 439 and 542 timeframes.


\subsubsection{CamCAN}
In the fMRI \emph{CamCAN} dataset, 647 participants aged from 18 to 88 years are watching Alfred Hitchcock's "Bang! You're Dead" (edited so that it lasts only 8 minutes).
% 
CamCAN consists of data obtained from the CamCAN repository (available at \url{http://www.mrc-cbu.cam.ac.uk/datasets/camcan/}) (see \cite{taylor2017cambridge} and \cite{shafto2014cambridge}).
% 
We use all available subjects and runs yielding 647 participants and 1 run of 193 timeframes.


\subsubsection{Raiders}
The \emph{RAIDERS} dataset reproduces the protocol described
in~\cite{haxby2011common}. 10 participants are watching the movie "Raiders
of the Lost Ark". This dataset pertains to the Individual Brain Charting
dataset~\cite{ibc, ibc2}. 
% 
We use full brain data of 10 subjects split in 9 runs of respectively 374, 297, 314, 379, 347, 346, 350, 353 and 211 timeframes.
%
Note that the Raiders dataset is different from the one used in~\cite{chen2015reduced}, as it involves different subjects, and because data were acquired at NeuroSpin using a 3T scanner with an isotropic spatial resolution of 1.5 mm.
The \emph{raiders-full} dataset~\cite{ibc, ibc2} is an extension of the \emph{raiders} dataset where the first two scenes of the movie are shown twice (130 mins).

\subsubsection{CLIPS}
The CLIPS dataset reproduces the protocol of original studies described in
\cite{nishimoto2011reconstructing} and \cite{huth2012continuous}. 10
participants are exposed to short clips. The data were acquired in 17 runs of 325 timeframes. 
%
The CLIPS dataset also pertains to the Individual Brain Charting dataset
(\cite{ibc, ibc2}).
%
The CLIPS and RAIDERS data are available in OpenNeuro under the identification
number: ds002685. Protocols on the visual stimuli presented are available in a dedicated repository on Github: \url{https://github.com/hbp-brain-charting/public_protocols}.

Unless stated otherwise we use spatially unsmoothed data, except for the
\emph{sherlock} dataset, for which the available data are already preprocessed
with a 6\,mm spatial smoothing. The temporal resolution or repetition time (TR) is 2s for all datasets except for the Sherlock dataset where the TR is 1.5s.
%

A summary about the size of each dataset is available in Table~\ref{tab:dataset_desc2}. Note in particular that all datasets have been resampled to 2mm isotropic resolution, leading to 212,445 voxels in the brain mask.
\begin{table}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		\textbf{Dataset} & \textbf{Subjects} & \textbf{Runs} & \textbf{Average run} & \textbf{Voxels} \\
                     && & \textbf{length} & \textbf{(per subject)} \\
                     && & \textbf{(in timeframes)} &  \\
                     &$m$& $ $ &  &$v$  \\
		\hline
		CLIPS & 10 & 17 & 325 & 212445\\ 
		\hline
		SHERLOCK & 16 & 5 & 395 & 212445 \\ 
		\hline
		RAIDERS & 10 & 9 & 330 & 212445 \\
		\hline 
		FORREST & 19 & 7 & 465 & 212445\\
		\hline
		CamCAN & 647 & 1 & 193 & 212445 \\
		\hline
	\end{tabular}
  \caption{\textbf{Datasets description}}
  \label{tab:dataset_desc2}
\end{table}

\subsection{An example of univariate analysis: analyzing task fMRI data via the general linear model}
\label{sec:glm}
In this section, we describe a framework successfully applied to identify brain regions involved in specific tasks: the general linear model
(GLM)~\cite{friston1995analysis}. We refer the reader to
Poline~\cite{poline2012general} for a more detailed description of the model and only cover here what we consider to be the most important parts.

We associate to each image $t$ a set of numbers $\sbb(t)$ that describe the experiment and
nuisance parameters.
For instance, in an experiment where the subject is either asked to listening a
sentence or reading a sentence we could have the association: $\sbb(t) = (\phi(t), \tau(t), x(t), y(t),
z(t))$ where $\phi(t)=1$ if the subject is reading a sentence and $0$ otherwise, $\tau(t)=1$
if the subject is listening to a sentence and $0$ otherwise and  $x(t), y(t), z(t)$ describe the
position of the head. While $\phi$ and $\tau$ describe the experiment, $x, y, z$
describe nuisance parameters.
Note that in practice we use many more nuisance regressors, such
as parameters describing the rotation of the head, heartbeats, respiration
rhythm and really any other parameter that might introduce artifacts. We also
usually convolve the regressors describing the experiment with the hemodynamic
function so that they are closer to the actual brain response and sometimes also its derivative to account for small temporal deviations from our model of hemodynamic response.
We call $S \in \RR^{k, n}$ the \emph{design matrix} such that column
$t$ of $S$ is given by $\sbb(t)$.
Then, the general linear model sees the data of one subject $X \in \RR^{v \times n}$ as a linear combination of the
design matrix $S$ with additive noise $N$.
\begin{align}
X = A S + N
\end{align}
where $A \in \RR^{v \times k}$ contains $k$ spatial maps in the sense that column $j$
of $A$ can be plotted as a brain image representing the localization of activity
described by the row $j$ of $S$.
The noise is often assumed to be Gaussian with unit variance so that $A$ can be obtained as the
result of a linear regression. Another common hypothesis is to assume temporal
correlation of the noise in the form of an AR-1 process. In this case, we 
consider instead the data $XB$ where $B \in \RR^{n \times n}$ is chosen so that the
noise $BN$ has no temporal correlation allowing us to perform linear regression.

The result of the GLM procedure is often given by \emph{contrasts maps} where
the spatial maps corresponding to conditions of interest are subtracted.
In our reading versus listening example, we would typically display the first column of
$A$ (that corresponds to $\phi$ which describes the activation related to
reading a sentence) minus
the second column of $A$ (that corresponds to $\tau$ which describes the
activation related to listening to a sentence). An example of ``reading versus listening contrast is displayed in
Figure~\ref{fig:ibc_contrast}.

\begin{figure}
  \includegraphics[scale=0.3]{figures/neuroscience/spatial_map.png}
  \caption{Contrast ``sentence listening versus sentence reading'' computed from the fMRI data of one
    subject in the IBC dataset~\cite{ibc, ibc2}. This contrast was downloaded
    from neurovault~\cite{gorgolewski2015neurovault} (collection 2138 subject 1 session 0) .}
  \label{fig:ibc_contrast}
\end{figure}

In this thesis, we always work with unthresholded contrast maps like the
one in Figure~\ref{fig:ibc_contrast}. For interpretation purposes, contrast maps
are usually z-scored and thresholded to keep only activity that is significantly
different from zero.
The GLM model is called univariate since interactions between voxels are not
modeled.
Univariate methods are often criticized for their inability to
capture well correlations and interactions between brain-wide measurements.
This makes it difficult to precisely locate brain functions from brain maps. An approach to overcome this issue is to train classifiers to \emph{decode} brain maps, i.e to discriminate between different stimulus of task
types~\cite{shirer_decoding_2012,varoquaux_how_2014,loula_decoding_2018}. When linear classifiers are used, the weights of this classifiers localize the brain functions.
This approach can be more powerful, as classifiers take correlations between
voxels into account. Decoding is also popular for individual imaging-based diagnosis.

\section{Magneto electro encephalography (MEG)}
Most material in this section is inspired from the book of Riitta Hari and Aina
Puce~\cite{hari2017meg}.

\subsection{Principle of MEG}
When a neuron fires, it emits a current that generates a magnetic field. By
recording the magnetic field close to the skull, we gain insight on neural
activity.

A limiting factor is that the magnetic fields induced by neuronal currents are
extremely weak (on the order of $10 fT$) which is much lower than the ambient magnetic noise ($10^8 fT$). Therefore recordings are performed in a shielded room and extremely sensitive magnetometers are used.
The best current tools can measure the magnetic field generated by approximately 50~000 neurons oriented in the same direction.

MEG recording device also include gradiometers in addition to magnetometers.
These are sensitive to the local variations of the magnetic field. However in our experiments, we only use the magnetometers data.

MEG has a temporal resolution on the order of the ms which is essentially the same as electroencephalography (EEG). This is much better than fMRI. The spatial
resolution is similar to that of EEG and is on the order of the centimeter.
In general the brain sources are slightly better localized in MEG since the
magnetic field is not affected by changes in conductivity in the head.


\subsection{Solving the inverse problem}
In order to locate activation from the brain measurements, we need to solve an inverse problem: what kind of sources can generate the magnetic field we
observe ? This section gives an overview of the sLORETA
method~\cite{pascual2002standardized} and is strongly inspired from the tutorial
of the authors~\cite{pascual2007discrete}.

From a vector describing the 3D current density inside the brain $\jb \in \RR^{3 \times v}$
($v$ is the number of voxels) we
can predict the magnetic field recorded by the sensors $\bb \in \RR^p$ ($p$ is
the number of sensors) by solving Maxwell's
equations. This is called the \emph{forward model}. Models describing the
geometry of the head (head models) are used to provide an approximate solution.
We have therefore
\begin{align}
  \bb = K \jb
  \label{eq:maxwell}
\end{align}
where $K \in \RR^{p \times 3v}$ is the solution to the forward model.
$K$ can be seen as $K  = [K_1 \dots K_{v}]$ where $K_i \in \RR^{p \times 3}$ describes how voxel $i$ contributes to the measured magnetic field $\bb$.

Note that if $\bb$ and $K$ are given there is an infinite number of possible
$\jb$ that satisfy equation~\eqref{eq:maxwell}, so the inverse problem must be regularized in order to select a solution among all possible ones.
A common parametrization is to assume that the current at voxel $i$, $\jb_i \in
\RR^3$ verifies:
\begin{align}
\jb_i = (K_i^{\top} C K_i)^{-\frac12} K_i^{\top} C \bb
\end{align}
for a symmetric matrix $C \in \RR^{p \times p}$.
In sLORETA, we have $C = (K K^{\top} + \alpha I)^{\dagger}$ where $\dagger$
represents Moore's pseudo inverse, $I$ is the identity matrix and $\alpha$ is an hyperparameter. 

Taking a point wise source $\ab \in \RR^{3}$ at voxel $i_*$
equation~\eqref{eq:maxwell} yields $\bb = K_{i_*} \ab$.
Then, $\jb_i = (K_i^{\top} C K_i) K_{i_*} \ab$ is such that $\| \jb_i \|^2$ is maximum at $i=i_*$ showing that the method can correctly recover point sources.

\subsection{Preprocessing steps}
This section is inspired from the preprocessing recommandations
in~\cite{jas2018reproducible} and the book of Riitta Hari and Aina
Puce~\cite{hari2017meg}. 

\subsubsection{Temporal filtering}
Temporal filtering is performed in two steps. First an analogous pass band
filter selects a large band of frequencies between $0.01 Hz$ and $200Hz$.
Then, a digital filtering is applied. Typically, a low-pass filtering with
cut-off frequency at $40 Hz$ is used as it is removes the line frequency at
$50 Hz$ while keeping most of the brain's signals.

\subsubsection{Independent component analysis}
Independent component analysis (ICA) can be used to isolate artifacts due to
heart beating or muscle contraction. As will be seen in section~\ref{sec:ica}.
ICA extracts independent components from the data. The data can be cleaned by
removing components corresponding to artifacts~\cite{jung1998extended}.

\subsubsection{Maxwell filtering}
Maxwell filtering also called signal space separation
(SSS)~\cite{taulu2006spatiotemporal} identifies the contributions to the
magnetic field from brain sources outside the brain and removes it.
This decreases the effects of outside noise and even allows to scan subjects with
implanted stimulators.


\subsection{Experimental designs}
In magneto-encephalography, we measure \emph{event related fields} (ERF) related to an
\emph{evoked response} in the brain.
Experiments are often repeated several times yielding a number of \emph{trials}.
By averaging the event related fields over trials, the signal to noise ration increases.

\subsection{MEG datasets}
\label{sec:meg:datasets}
In this section, we give examples of MEG datasets. These examples are used in
the rest of the thesis to evaluate the methods we develop.

The \emph{Sinusoidal Phantom MEG} dataset uses data collected with a realistic head phantom, which is a plastic device mimicking real electrical brain components.
% 
Eight current dipoles positioned at different locations can be switched on or off.
% 
We only consider the 102 magnetometers.
% 
An epoch corresponds to 3\,s of MEG signals where a dipole is switched on for 0.4\,s with an oscillation at 20\,Hz and a peak-to-peak amplitude of 200\,nAm.
% 
We have access to $100$ epochs per dipole.
%
Maxwell filtering is applied on the data as well as low-pass filtering with a cut-off
frequency at 40 Hz.

The \emph{Elekta Phantom MEG} dataset also uses data collected with a realistic
head phantom and is available as part of the Brainstorm
application~\cite{tadel2011brainstorm}.
This dataset uses 32 dipoles positioned at different locations. Like in the
\emph{Sinusoidal Phantom MEG} dataset, we only
consider the 102 magnetometers and apply Maxwell filtering and low-pass filtering
with a cut-off frequency at 40 Hz. The dipoles emit a signal at either a strong, medium or low
amplitude yielding 3 different datasets.
We use the dataset where the emitted signal is very strong to recover the true signal
by performing a PCA with 1 component.
Then we work with the dataset where the emitted signal is the weakest.
Each epoch corresponds to 301 samples and 20 epochs are available in total.

The \emph{CamCAN} dataset~\cite{shafto2014cambridge}
contains the MEG data of 647 different
subjects exposed to an audio-visual stimuli. More precisely, subjects are presented simultaneously an
auditory stimuli lasting 300ms at frequency 300, 600 or 1200 Hz  and a
checkerboard pattern lasting 34ms. 120 trials are available.

\section{Conclusion}
In this chapter, we described the principles on which fMRI and MEG imaging
are based as well as the standard preprocessing pipelines and the datasets used
in this thesis.

In the next chapter, we review several methods to perform unsupervised analysis
of neuroimaging data.

